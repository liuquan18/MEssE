! Copyright (c) 2024 The YAC Authors
!
! SPDX-License-Identifier: BSD-3-Clause

MODULE toy_ocn

  USE mpi
  USE yac
  USE yac_utils, ONLY : yac_test_gulfstream_c
  USE toy_common, ONLY : read_icon_grid, nsteps, define_fields, &
                         send_field, receive_field, &
                         max_char_length

  IMPLICIT NONE

  PRIVATE

  INTEGER :: t, ierror

  ! Basic string paramters
  CHARACTER(LEN=max_char_length), PARAMETER :: yaml_filename = "coupling.yaml"
  CHARACTER(LEN=max_char_length), PARAMETER :: grid_filename = "grids/icon_grid_0036_R02B04_O.nc"
  CHARACTER(LEN=max_char_length), PARAMETER :: comp_name = "ocn_comp"
  CHARACTER(LEN=max_char_length), PARAMETER :: grid_name = "ocn_grid"

  ! IDs and communicator generated by YAC
  INTEGER :: comp_id
  INTEGER :: comp_comm = MPI_COMM_WORLD
  INTEGER :: comp_rank
  INTEGER :: grid_id
  INTEGER :: cell_point_id
  INTEGER :: field_taux_id
  INTEGER :: field_tauy_id
  INTEGER :: field_sfwflx_id
  INTEGER :: field_sftemp_id
  INTEGER :: field_thflx_id
  INTEGER :: field_iceatm_id
  INTEGER :: field_sst_id
  INTEGER :: field_oceanu_id
  INTEGER :: field_oceanv_id
  INTEGER :: field_iceoce_id

  ! Basic decomposed grid information
  INTEGER                       :: num_vertices
  INTEGER                       :: num_cells
  INTEGER                       :: num_vertices_per_cell
  INTEGER, ALLOCATABLE          :: cell_to_vertex(:,:)
  DOUBLE PRECISION, ALLOCATABLE :: x_vertices(:)
  DOUBLE PRECISION, ALLOCATABLE :: y_vertices(:)
  DOUBLE PRECISION, ALLOCATABLE :: x_cells(:)
  DOUBLE PRECISION, ALLOCATABLE :: y_cells(:)
  INTEGER, ALLOCATABLE          :: cell_sea_land_mask(:)
  INTEGER, ALLOCATABLE          :: global_cell_id(:)

  ! Buffer for field data
  DOUBLE PRECISION, DIMENSION(:,:), ALLOCATABLE :: &
       taux, tauy, sfwflx, sftemp, thflx, iceatm, sst, oceanu, oceanv, iceoce

  PUBLIC :: main_ocn

CONTAINS

  SUBROUTINE main_ocn(comm)
    INTEGER, INTENT(IN) :: comm

    comp_comm = comm

    ! Read coupling configuration file
    ! TODO
    CALL yac_fread_config_yaml(yaml_filename)
    ! END TODO

    ! Define local component
    ! TODO
    CALL yac_fdef_comp(comp_name, comp_id)
    ! END TODO

    ! Retrieve communicator for OCN component
    ! TODO
    CALL yac_fget_comp_comm(comp_id, comp_comm)
    ! END TODO
    CALL MPI_Comm_rank(comp_comm, comp_rank, ierror)

    ! Read the grid and distribute it among all OCN processes
    CALL read_icon_grid( &
         grid_filename, comp_comm, cell_to_vertex, x_vertices, &
         y_vertices, x_cells, y_cells, cell_sea_land_mask, global_cell_id)
    num_vertices = SIZE(x_vertices)
    num_cells = SIZE(x_cells)
    num_vertices_per_cell = SIZE(cell_to_vertex, 1)

    ! Define local part of the grid
    ! TODO
    CALL yac_fdef_grid ( &
         grid_name, num_vertices, num_cells, num_vertices_per_cell, &
         x_vertices, y_vertices, cell_to_vertex, grid_id )
    ! END TODO

    ! Define location of the actual data (on cell centers)
    ! TODO
    CALL yac_fdef_points ( &
         grid_id, num_cells, YAC_LOCATION_CELL, &
         x_cells, y_cells, cell_point_id )
    ! END TODO

    ! Set global cell ids
    ! TODO
    CALL yac_fset_global_index(global_cell_id, YAC_LOCATION_CELL, grid_id)
    ! END TODO

    ! Set mask for cell centers
    ! TODO
    CALL yac_fset_mask(cell_sea_land_mask < 0, cell_point_id)
    ! END TODO

    ! Define fields
    CALL define_fields( &
         comp_id, cell_point_id, field_taux_id, field_tauy_id, field_sfwflx_id, &
         field_sftemp_id, field_thflx_id, field_iceatm_id, field_sst_id, &
         field_oceanu_id, field_oceanv_id, field_iceoce_id)

    ! Complete definitions and compute interpolations
    ! TODO
    CALL yac_fenddef()
    ! END TODO

    ! Initialise fields
    CALL init_fields()

    ! Execute model time loop
    DO t = 1, nsteps

       ! Simulate ocn timestep
       CALL sim_ocn_timestep(t)

       ! Exchange data with atm component
       CALL couple_to_atm()

    END DO ! time loop

  END SUBROUTINE main_ocn

  SUBROUTINE init_fields()

    INTEGER :: i

    ! Allocate output field buffers
    ALLOCATE( &
      sst(num_cells, 1), oceanu(num_cells, 1), oceanv(num_cells, 1), &
      iceoce(num_cells, 5))

    ! Initialise output field buffer with dummy data
    DO i = 1, num_cells
      sst(i,1) = yac_test_gulfstream_c(x_cells(i), y_cells(i))
    END DO
    oceanu(:,1) = 120.0d0
    oceanv(:,1) = 130.0d0
    iceoce(:,1) = 140.1d0
    iceoce(:,2) = 140.2d0
    iceoce(:,3) = 140.3d0
    iceoce(:,4) = 140.4d0
    iceoce(:,5) = 140.5d0

    ! Allocate input field buffers
    ALLOCATE( &
      taux(num_cells, 2), tauy(num_cells, 2), sfwflx(num_cells, 3), &
      sftemp(num_cells, 1), thflx(num_cells, 4), iceatm(num_cells, 4))

    ! Initialise input field buffer with zero
    taux(:,1) = 0.0d0
    taux(:,2) = 0.0d0
    tauy(:,1) = 0.0d0
    tauy(:,2) = 0.0d0
    sfwflx(:,1) = 0.0d0
    sfwflx(:,2) = 0.0d0
    sfwflx(:,3) = 0.0d0
    sftemp(:,1) = 0.0d0
    thflx(:,1) = 0.0d0
    thflx(:,2) = 0.0d0
    thflx(:,3) = 0.0d0
    thflx(:,4) = 0.0d0
    iceatm(:,1) = 0.0d0
    iceatm(:,2) = 0.0d0
    iceatm(:,3) = 0.0d0
    iceatm(:,4) = 0.0d0

  END SUBROUTINE init_fields

  SUBROUTINE sim_ocn_timestep(timestep)

    INTEGER, INTENT(IN) :: timestep

    ! Do an ocean timestep

    ! ...

    CALL MPI_Barrier(comp_comm, ierror)
    IF (comp_rank == 0) &
      PRINT "('--- ',A3,' timestep ',I2,' ---')", comp_name, timestep

  END SUBROUTINE sim_ocn_timestep

  SUBROUTINE couple_to_atm()

    ! --------------------
    ! Send fields to ocean
    ! --------------------

    ! Send sea surface temperature
    CALL send_field(field_sst_id, sst)

    ! Send zonal velocity
    CALL send_field(field_oceanu_id, oceanu)

    ! Send meridional velocity
    CALL send_field(field_oceanv_id, oceanv)

    ! Send Ice thickness, concentration, T1 and T2
    CALL send_field(field_iceoce_id, iceoce)

    ! -------------------------
    ! Receive fields from ocean
    ! -------------------------

    ! Recieve meridional wind stress
    CALL receive_field(comp_name, field_taux_id, taux)

    ! Recieve zonal  wind stress
    CALL receive_field(comp_name, field_tauy_id, tauy)

    ! Recieve surface fresh water flux
    CALL receive_field(comp_name, field_sfwflx_id, sfwflx)

    ! Recieve surface temperature
    CALL receive_field(comp_name, field_sftemp_id, sftemp)

    ! Recieve total heat flux
    CALL receive_field(comp_name, field_thflx_id, thflx)

    ! Recieve ice temperatures and melt potential
    CALL receive_field(comp_name, field_iceatm_id, iceatm)

  END SUBROUTINE couple_to_atm

END MODULE toy_ocn

PROGRAM main_ocn_program
  USE mpi
  USE yac
  USE toy_ocn, ONLY : main_ocn

  IMPLICIT NONE

  INTEGER :: ierror

  ! Initialise MPI
  CALL MPI_Init(ierror)

  ! Initialise the YAC
  ! TODO
  CALL yac_finit()
  ! END TODO

  ! Run atmosphere model
  CALL main_ocn(MPI_COMM_WORLD)

  ! Finalise YAC
  ! TODO
  CALL yac_ffinalize()
  ! END TODO

  ! Finalise MPI
  CALL MPI_Finalize(ierror)

END PROGRAM main_ocn_program
